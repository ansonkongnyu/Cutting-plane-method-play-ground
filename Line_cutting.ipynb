{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "TyYPUOkMm7-W"
      },
      "id": "TyYPUOkMm7-W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gurobipy\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from gurobipy import *\n",
        "\n",
        "\n",
        "def GurobiIntSolve(A,b,c):\n",
        "\tc = -c # Gurobi default is maximization\n",
        "\tvarrange = range(c.size)\n",
        "\tcrange = range(b.size)\n",
        "\tm = Model('LP')\n",
        "\tm.params.OutputFlag = 0 #suppres output\n",
        "\tX = m.addVars(varrange, lb=0.0, ub=GRB.INFINITY, vtype=GRB.INTEGER,\n",
        "                 obj=c,\n",
        "                 name=\"X\")\n",
        "\tC = m.addConstrs((sum(A[i,j]*X[j] for j in varrange)==b[i] for i in crange),'C')\n",
        "\tm.params.Method = -1 # primal simplex Method = 0\n",
        "\tm.optimize()\n",
        "\t# obtain results\n",
        "\tsolution = []; \n",
        "\tfor i in X:\n",
        "\t\tsolution.append(X[i].X);\n",
        "\tsolution = np.asarray(solution)\n",
        "\treturn m.ObjVal,solution\n",
        "\n",
        "\n",
        "def GurobiSolve(A,b,c,Method=0):\n",
        "\t#print('solving starts')\n",
        "\tc = -c # Gurobi default is maximization\n",
        "\tvarrange = range(c.size)\n",
        "\tcrange = range(b.size)\n",
        "\tm = Model('LP')\n",
        "\tm.params.OutputFlag = 0 #suppress output\n",
        "\tX = m.addVars(varrange, lb=0.0, ub=GRB.INFINITY, vtype=GRB.CONTINUOUS,\n",
        "                 obj=c,\n",
        "                 name=\"X\")\n",
        "\tC = m.addConstrs((sum(A[i,j]*X[j] for j in varrange)==b[i] for i in crange),'C')\n",
        "\tm.params.Method = Method # primal simplex Method = 0\n",
        "\t#print('start optimizing...')\n",
        "\tm.optimize()\n",
        "\t# obtain results\n",
        "\tsolution = []; basis_index = []; RC = []\n",
        "\tfor i in X:\n",
        "\t\tsolution.append(X[i].X);\n",
        "\t\tRC.append(X[i].getAttr('RC'))\n",
        "\t\tif X[i].getAttr('VBasis') == 0:\n",
        "\t\t\tbasis_index.append(i)\n",
        "\tsolution = np.asarray(solution)\n",
        "\tRC = np.asarray(RC)\n",
        "\tbasis_index = np.asarray(basis_index)\n",
        "\t#print('solving completes')\n",
        "\treturn m.ObjVal,solution,basis_index,RC\n",
        "\n",
        "\n",
        "def computeoptimaltab(A,b,RC,obj,basis_index):\n",
        "\t'''\n",
        "\tA - A matrix, b - constraint, RC - reduced cost, basis_index - basis \n",
        "\t'''\n",
        "\tm,n = A.shape\n",
        "\tassert m == b.size; assert n == RC.size\n",
        "\tB = A[:,basis_index]\n",
        "\ttry:\n",
        "\t\tINV = np.linalg.inv(B)\n",
        "\texcept:\n",
        "\t\tprint('basisindex length:', basis_index.size)\n",
        "\t\tprint('Ashape:', A.shape)\n",
        "\t\traise ValueError\n",
        "\tx = np.dot(INV,b)\n",
        "\tA_ = np.dot(INV,A)\n",
        "\tfirstrow = np.append(-obj,RC)\n",
        "\tsecondrow = np.column_stack((x,A_))\n",
        "\ttab = np.vstack((firstrow,secondrow))\n",
        "\treturn tab\n",
        "\n",
        "\n",
        "def generatecutzeroth(row):\n",
        "\t###\n",
        "\t# generate cut that includes cost/obj row as well\n",
        "\t###\n",
        "\tn = row.size\n",
        "\ta = row[1:n]\n",
        "\tb = row[0]\n",
        "\tcut_a = a - np.floor(a)\n",
        "\tcut_b = b - np.floor(b)\n",
        "\treturn cut_a,cut_b\n",
        "\n",
        "\n",
        "def updatetab(tab,cut_a,cut_b,basis_index):\n",
        "\tcut_a = -cut_a\n",
        "\tcut_b = -cut_b\n",
        "\tm,n = tab.shape\n",
        "\tA_ = tab[1:m,1:n]; b_ = tab[1:m,0]; c_ = tab[0,1:n]; obj = tab[0,0]\n",
        "\tAnew1 = np.column_stack((A_,np.zeros(m-1)))\n",
        "\tAnew2 = np.append(cut_a,1)\n",
        "\tAnew = np.vstack((Anew1,Anew2))\n",
        "\tbnew = np.append(b_,cut_b)\n",
        "\tcnew = np.append(c_,0)\n",
        "\tM1 = np.append(obj,cnew)\n",
        "\tM2 = np.column_stack((bnew,Anew))\n",
        "\tnewtab = np.vstack((M1,M2))\n",
        "\tbasis_index = np.append(basis_index,n-1)\n",
        "\treturn newtab,basis_index,Anew,bnew"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhgJcKRfnDhV",
        "outputId": "ae1d79f7-129e-4309-d733-07c2a007ea9e"
      },
      "id": "MhgJcKRfnDhV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.7/dist-packages (10.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zWt9iszisZ1j"
      },
      "id": "zWt9iszisZ1j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def phase_two(x,basis_index,A,b,c):\n",
        "\t'''\n",
        "\texecutes phase_two of generic simplex algorithm\n",
        "\tx: starting BFS\n",
        "\tbasis_index: index of variables that are basic feasible in x\n",
        "\tA: constraint matrix\n",
        "\tb: constraint\n",
        "\tc: cost\n",
        "\t'''\n",
        "\t# check consistency of basis_index and x\n",
        "\tfor i in range(len(x)):\n",
        "\t\tif i not in basis_index:\n",
        "\t\t\tif abs(x[i])>1e-8:\n",
        "\t\t\t\tsys.exit('inconsistent input')\n",
        "\t# compute initial tab\n",
        "\t(m,n) = np.shape(A)\n",
        "\tB = A[:,basis_index]\n",
        "\tcB = c[basis_index]\n",
        "\tinvB = np.linalg.inv(B)\n",
        "\tM1 = np.dot(invB,A)\n",
        "\tM2 = np.dot(invB,b)\n",
        "\tM3 = c - np.dot(cB,M1)\n",
        "\tM4 = -np.dot(cB,M2)\n",
        "\tA_b = np.column_stack((M1,M2))\n",
        "\tc_o = np.append(M3,M4)\n",
        "\ttab = np.vstack((A_b,c_o))\n",
        "\tcounter = 1\n",
        "\tvar_selection_order = []\n",
        "\t# iteration\n",
        "\twhile np.sum(tab[m,0:n]<0)>1e-8:\n",
        "\t\t# find column with smallest index\n",
        "\t\tjset = np.where(tab[m,0:n]<-0)\n",
        "\t\tj = jset[0][0]\n",
        "\t\t# print out tab for error checking\n",
        "\t\t# print 'iteration',counter \n",
        "\t\t# print 'tab',tab\n",
        "\t\t# check u<0\n",
        "\t\tif np.sum(tab[0:m,j]>1e-8)<1:\n",
        "\t\t\tbounded = 0\n",
        "\t\t\treturn\n",
        "\t\t# find u>0 and compute ratio for comparison\n",
        "\t\t# bland's rule\n",
        "\t\tu = tab[0:m,j]\n",
        "\t\txB = x[basis_index]\n",
        "\t\tratio = np.zeros_like(xB)\n",
        "\t\tfor i in range(len(xB)):\n",
        "\t\t\tif u[i]>1e-10:\n",
        "\t\t\t\tratio[i] = xB[i]/(u[i]+0.0)\n",
        "\t\t\telse:\n",
        "\t\t\t\tratio[i] = -10\n",
        "\t\tlset = np.where(ratio==np.min(ratio[u>1e-10]))\n",
        "\t\tl = lset[0][0]\n",
        "\t\t# change basis\n",
        "\t\tfor i in range(m+1):\n",
        "\t\t\tif i!=l:\n",
        "\t\t\t\ttab[i,:] = tab[i,:] + (-tab[i,j]/(tab[l,j]+0.0)) * tab[l,:]\n",
        "\t\t\t\ttab[i,j] = 0 # for numerical stability #\n",
        "\t\ttab[l,:] = tab[l,:]/(tab[l,j]+0.0)\n",
        "\t\t# update basis index\n",
        "\t\tbasis_index[l] = j\n",
        "\t\t# update solution\n",
        "\t\tx = np.zeros(n)\n",
        "\t\tX = tab[0:m,n]\n",
        "\t\tfor i in range(len(basis_index)):\n",
        "\t\t\tidxset = np.where(tab[0:m,basis_index[i]]==np.max(tab[0:m,basis_index[i]]))\n",
        "\t\t\tidx = idxset[0]\n",
        "\t\t\tif len(idx)>1:\n",
        "\t\t\t\tprint('tab')\n",
        "\t\t\t\tprint(tab)\n",
        "\t\t\t\tprint(tab[0:m,basis_index[i]])\n",
        "\t\t\t\tprint('basis',basis_index[i])\n",
        "\t\t\t\tprint('idx',idx)\n",
        "\t\t\t\tprint('error of multiple indices')\n",
        "\t\t\t\tsys.exit()\n",
        "\t\t\tidx = idx[0]\n",
        "\t\t\tx[basis_index[i]] = X[idx]\n",
        "\t\tcounter += 1\n",
        "\t\tvar_selection_order.append(l)\n",
        "\t\tif counter > 10000:\n",
        "\t\t\tprint(counter)\n",
        "\t\t\tprint(var_selection_order)\n",
        "\t\t\tsys.exit('iteration exceeds maxiter')\n",
        "\tbounded = 1\n",
        "\t## change the layout\n",
        "\tm,n = tab.shape\n",
        "\tA_ = tab[0:m-1,0:n-1]\n",
        "\tb_ = tab[0:m-1,n-1]\n",
        "\tcbar = tab[m-1,0:n-1]\n",
        "\tobj = tab[m-1,n-1]\n",
        "\tM1 = np.append(obj,cbar)\n",
        "\tM2 = np.column_stack((b_,A_))\n",
        "\ttab = np.vstack((M1,M2))\n",
        "\treturn tab,bounded,basis_index\n",
        "\n",
        "\n",
        "def phase_one(A,b,c):\n",
        "\t'''\n",
        "\texecutes phase one of generic simplex algorithm\n",
        "\tA: constraint matrix\n",
        "\tb: constraint\n",
        "\tc: cost\n",
        "\t'''\n",
        "\t# modify the input\n",
        "\tm,n = np.shape(A)\n",
        "\tfor i in range(m):\n",
        "\t\tif b[i]<-1e-10:\n",
        "\t\t\tA[i,:] = -A[i,:]\n",
        "\t\t\tb[i] = -b[i]\n",
        "\t# solve an aux problem\n",
        "\tA_aux = np.concatenate((A,np.eye(m)),axis=1)\n",
        "\tb_aux = b\n",
        "\tc_aux = np.append(np.zeros(n),np.ones(m))\n",
        "\tx = np.append(np.zeros(n),b)\n",
        "\tbasis_index = np.arange(n,n+m)\n",
        "\ttab,bounded,basis_index = phase_two(x,basis_index,A_aux,b_aux,c_aux)\n",
        "\t## change the layout\n",
        "\tm1,n1 = tab.shape\n",
        "\tA_ = tab[1:m1,1:n1]\n",
        "\tb_ = tab[1:m1,0]\n",
        "\tcbar = tab[0,1:n1]\n",
        "\tobj = tab[0,0]\n",
        "\tM1 = np.append(cbar,obj)\n",
        "\tM2 = np.column_stack((A_,b_))\n",
        "\ttab = np.vstack((M2,M1))\n",
        "\t# check feasibility\n",
        "\tif abs(tab[m,n+m]) < 1e-8:\n",
        "\t\tfeasible = 1\n",
        "\telse:\n",
        "\t\tfeasible = 0\n",
        "\t\tbasis_index = []\n",
        "\t\ttab = []\n",
        "\t\treturn x,basis_index,feasible,tab,A,b\n",
        " \t# if feasible, drive artificial var out of the set\n",
        "\twhile np.sum(basis_index>n-1)>0:\n",
        "\t\tlset = np.where(basis_index>n-1)\n",
        "\t\tl = lset[0][0]\n",
        "\t\t# if all are zeros, eliminte the redundant row\n",
        "\t\tif np.sum(abs(tab[l,0:n])) < 1e-5:\n",
        "\t\t\tindex = []\n",
        "\t\t\tfor ii in range(m):\n",
        "\t\t\t\tif ii!=l:\n",
        "\t\t\t\t\tindex.append(ii)\n",
        "\t\t\tbasis_index = basis_index[np.asarray(index)]\n",
        "\t\t\tA = A[np.asarray(index),:]\n",
        "\t\t\tb = b[np.asarray(index)]\n",
        "\t\t\tindex = np.append(index,m)\n",
        "\t\t\ttab = tab[np.asarray(index),:]\n",
        "\t\telse: # can find a nonzero element\n",
        "\t\t\tjset = np.where(abs(tab[l,0:n])>1e-5)\n",
        "\t\t\tj = jset[0][0]\n",
        "\t\t\tm,n = A.shape\n",
        "\t\t\tfor k in range(m):\n",
        "\t\t\t\tif k!=l:\n",
        "\t\t\t\t\ttab[k,:] = tab[k,:] + (-tab[k,j]/(0.0+tab[l,j])) * tab[l,:]\n",
        "\t\t\t\t\ttab[k,j] = 0 # for numerical stability #\n",
        "\t\t\ttab[l,:] = tab[l,:]/(0.0+tab[l,j])\n",
        "\t\t\tbasis_index[l] = j\n",
        "\tm = len(basis_index)\n",
        "\tx = np.zeros(n)\n",
        "\tX = tab[0:m,n+m]\n",
        "\tfor i in range(m):\n",
        "\t\tidxset = np.where(tab[0:m,basis_index[i]]>0.5)\n",
        "\t\tidxset = idxset[0]\n",
        "\t\tif len(idxset)>1:\n",
        "\t\t\tprint('idx set size exceeds 1')\n",
        "\t\t\tsys.exit()\n",
        "\t\telse:\n",
        "\t\t\tx[basis_index[i]] = X[idxset[0]]\n",
        "\t## change the layout\n",
        "\tm,n = tab.shape\n",
        "\tA_ = tab[0:m-1,0:n-m]\n",
        "\tb_ = tab[0:m-1,n-1]\n",
        "\tcbar = tab[m-1,0:n-m]\n",
        "\tobj = tab[m-1,n-1]\n",
        "\tM1 = np.append(obj,cbar)\n",
        "\tM2 = np.column_stack((b_,A_))\n",
        "\ttab = np.vstack((M1,M2))\n",
        "\tA = A_\n",
        "\tb = b_\n",
        "\treturn x,basis_index,feasible,tab,A,b\n",
        "\n",
        "\n",
        "def simplexalgo(A,b,c):\n",
        "\tx,basis_index,feasible,tab,A,b = phase_one(A,b,c)\n",
        "\tif feasible:\n",
        "\t\ttab,bounded,basis_index = phase_two(x,basis_index,A,b,c)\n",
        "\telse:\n",
        "\t\tbounded = 0\n",
        "\treturn tab,bounded,feasible,basis_index\n",
        "\n",
        "\n",
        "def lexcolumn(l,tab):\n",
        "\tm,n = tab.shape\n",
        "\ttab = tab[:,1:n]\n",
        "\tindexset = np.where(tab[l+1,:]<0)\n",
        "\tindexset = indexset[0]\n",
        "\tif len(indexset)==0:\n",
        "\t\tj = []\n",
        "\t\treturn j\n",
        "\tcolumns = tab[:,indexset]\n",
        "\tfor i in range(len(indexset)):\n",
        "\t\tcolumns[:,i] = columns[:,i]/columns[l+1,i]\n",
        "\tfindlargestset = np.where(columns[0,:]==np.max(columns[0,:]))\n",
        "\tfindlargest = findlargestset[0]\n",
        "\tcounter = 1\n",
        "\twhile len(findlargest)>=2:\n",
        "\t\tntem,mtem= columns.shape\n",
        "\t\tcolumns = columns[1:ntem,findlargest]\n",
        "\t\tindexset = indexset[findlargest]\n",
        "\t\tfindlargestset = np.where(columns[0,:]==np.max(columns[0,:]))\n",
        "\t\tfindlargest = findlargestset[0]\n",
        "\t\tcounter += 1\n",
        "\t\tif counter > m - 1:\n",
        "\t\t\tprint('counter exceeds max num')\n",
        "\t\t\tsys.exit()\n",
        "\tj = indexset[findlargest]\n",
        "\treturn j\n",
        "\t\n",
        "\n",
        "def dualsimplexalgo(tab,basis_index):\n",
        "\t###\n",
        "\t# follow standard layout [obj,cbar;b,A]\n",
        "\t###\n",
        "\tm,n = tab.shape\n",
        "\tcc = 0\n",
        "\tvar_selection_order = []\n",
        "\t# modfy the tab to be column lex positive\n",
        "\tfor j in range(1,n):\n",
        "\t\tif (j-1) not in basis_index:\n",
        "\t\t\tcolumnfirstnonzeroset = np.where(abs(tab[0:m,j])>0)\n",
        "\t\t\tcolumnfirstnonzero = columnfirstnonzeroset[0][0]\n",
        "\t\t\tif tab[columnfirstnonzero,j]<0:\n",
        "\t\t\t\tif columnfirstnonzero==0:\n",
        "\t\t\t\t\traise ValueError('reduced cost is negative for non bfs variable')\n",
        "\t\t\t\t\t#exit.sys()\n",
        "\t\t\t\ttab[1:m,j] = -tab[1:m,j]\n",
        "\t# start iteration\n",
        "\twhile np.sum(tab[1:m,0]<-1e-10)>=1: # or <0\n",
        "\t\t#print 'iteration...'\n",
        "\t\t# choose the lth row with x_b[l]<0\n",
        "\t\tlset = np.where(tab[1:m,0]<0)\n",
        "\t\tl = lset[0][0]\n",
        "\t\t# check if lth rows are all positive\n",
        "\t\tif np.sum(tab[l+1,1:n]>=0)==n-1:\n",
        "\t\t\tprint('primal nonfeasible due to dual unbounded...')\n",
        "\t\t\t# dual unbounded, primal non feasible\n",
        "\t\t\tprint(tab[l+1,:])\n",
        "\t\t\tbounded = 1\n",
        "\t\t\tfeasible = 0\n",
        "\t\t\ttab = []; basis_index = []\n",
        "\t\t\treturn tab,bounded,feasible,basis_index\n",
        "\t\tcbar = tab[0,1:n]\n",
        "\t\tif np.sum(cbar<0)>=1:\n",
        "\t\t\traise ValueError('error due to negative cbar in dual simplex')\n",
        "\t\t\t#sys.exit()\n",
        "\t\t# choose the pivot column\n",
        "\t\tj = lexcolumn(l,tab)\n",
        "\t\t# update basis index\n",
        "\t\tbasis_index[l] = j\n",
        "\t\t# update tab\n",
        "\t\tfor i in range(m):\n",
        "\t\t\tif i!=l+1:\n",
        "\t\t\t\ttab[i,:] = tab[i,:] + (-tab[i,j+1]/(0.0+tab[l+1,j+1])) * tab[l+1,:]\n",
        "\t\t\t\ttab[i,j+1] = 0\n",
        "\t\ttab[l+1,:] = tab[l+1,:]/(0.0+tab[l+1,j+1])\n",
        "\t\tcc += 1\n",
        "\t\tvar_selection_order.append(l)\n",
        "\t\tif cc>1000:\n",
        "\t\t\tprint('dual simplex iteration exceeds max iter')\n",
        "\t\t\tprint(var_selection_order)\n",
        "\t\t\tsys.exit()\n",
        "\tbounded = 1\n",
        "\tfeasible = 1\n",
        "\treturn tab,bounded,feasible,basis_index\n",
        "\n",
        "\n",
        "def compute_solution_from_tab(tab,basis_index):\n",
        "\tm,n = tab.shape\n",
        "\tx = np.zeros(n-1)\n",
        "\tbasis_index = list(basis_index)\n",
        "\tfor i in range(len(basis_index)):\n",
        "\t\tx[basis_index[i]] = tab[i+1,0]\n",
        "\treturn x\n",
        "\n",
        "\n",
        "def SolveLP(A,b,c):\n",
        "\tc=-c\n",
        "\ttab,bounded,feasible,basis_index = simplexalgo(A,b,c)\n",
        "\tobj = -tab[0,0]\n",
        "\tsolution = compute_solution_from_tab(tab,basis_index)\n",
        "\tRC = tab[0,1:]\n",
        "\treturn obj,solution,basis_index,RC\n",
        "\n",
        "\n",
        "def computeoptimaltab(A,b,RC,obj,basis_index):\n",
        "\t'''\n",
        "\tA - A matrix, b - constraint, RC - reduced cost, basis_index - basis \n",
        "\t'''\n",
        "\tm,n = A.shape\n",
        "\tassert m == b.size; assert n == RC.size\n",
        "\tB = A[:,basis_index]\n",
        "\ttry:\n",
        "\t\tINV = np.linalg.inv(B)\n",
        "\texcept:\n",
        "\t\tprint('basisindex length:', basis_index.size)\n",
        "\t\tprint('Ashape:', A.shape)\n",
        "\t\traise ValueError\n",
        "\tx = np.dot(INV,b)\n",
        "\tA_ = np.dot(INV,A)\n",
        "\tfirstrow = np.append(-obj,RC)\n",
        "\tsecondrow = np.column_stack((x,A_))\n",
        "\ttab = np.vstack((firstrow,secondrow))\n",
        "\treturn tab\n",
        "\n",
        "\n",
        "def SolveLPtab(tab,c):\n",
        "\t# extract data from the tab\n",
        "\tm,n = tab.shape\n",
        "\t#print c.size,n\n",
        "\ttry:\n",
        "\t\tassert c.size == n-1\n",
        "\texcept:\n",
        "\t\tprint(c.size,tab.shape)\n",
        "\t\traise ValueError\n",
        "\tA = tab[1:m,1:n]; b = tab[1:n,0]\n",
        "\tobj,sol,basis,rc = SolveLP(A,b,c) # dual simplex 1\n",
        "\treturn obj,sol,basis,rc\t\n",
        "\n",
        "\n",
        "def SolveLPtabDual(tab,c,basis_index):\n",
        "\t# construct the entire tab\n",
        "\tc = -c\n",
        "\t#x = tab[:,0]\n",
        "\t#obj = -np.sum(c[basis_index] * x)\n",
        "\t#bigtab = np.append(obj,c)\n",
        "\t#bigtab = np.vstack((bigtab,tab))\n",
        "\tbigtab = tab\n",
        "\ttab,bounded,feasible,basis_index = dualsimplexalgo(bigtab,basis_index)\n",
        "\treturn tab,basis_index\n",
        "\n",
        "\n",
        "def generatecutzeroth(row):\n",
        "\t###\n",
        "\t# generate cut that includes cost/obj row as well\n",
        "\t###\n",
        "\tn = row.size\n",
        "\ta = row[1:n]\n",
        "\tb = row[0]\n",
        "\tcut_a = a - np.floor(a)\n",
        "\tcut_b = b - np.floor(b)\n",
        "\treturn cut_a,cut_b\n",
        "\n",
        "\n",
        "def generatecut_MIP(row,I,basis_index):\n",
        "\t'''\n",
        "\tgenerate cut for MIP\n",
        "\tI: set of vars required to be integers\n",
        "\t'''\n",
        "\tn = row.size\n",
        "\tb = row[0]\n",
        "\ta = row[1:n]\n",
        "\tf = a - np.floor(a)\n",
        "\tf0 = b - np.floor(b)\n",
        "\tcut_a = np.zeros(n-1)\n",
        "\tcut_b = 0\n",
        "\tfor i in range(n-1):\n",
        "\t\tif i not in basis_index:\n",
        "\t\t\tif i in I:\n",
        "\t\t\t\tif f[i]<=f0:\n",
        "\t\t\t\t\tcut_a[i] = f[i]/(f0+0.0)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcut_a[i] = (1-f[i])/(1+0.0-f0)\n",
        "\t\t\telse:\n",
        "\t\t\t\tif a[i]>=0:\n",
        "\t\t\t\t\tcut_a[i] = a[i]/(f0+0.0)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcut_a[i] = -a[i]/(1+0.0-f0)\n",
        "\tcut_b = 1\n",
        "\treturn cut_a,cut_b\t\n",
        "\n",
        "\n",
        "def updatetab(tab,cut_a,cut_b,basis_index):\n",
        "\tcut_a = -cut_a\n",
        "\tcut_b = -cut_b\n",
        "\tm,n = tab.shape\n",
        "\tA_ = tab[1:m,1:n]; b_ = tab[1:m,0]; c_ = tab[0,1:n]; obj = tab[0,0]\n",
        "\tAnew1 = np.column_stack((A_,np.zeros(m-1)))\n",
        "\tAnew2 = np.append(cut_a,1)\n",
        "\tAnew = np.vstack((Anew1,Anew2))\n",
        "\tbnew = np.append(b_,cut_b)\n",
        "\tcnew = np.append(c_,0)\n",
        "\tM1 = np.append(obj,cnew)\n",
        "\tM2 = np.column_stack((bnew,Anew))\n",
        "\tnewtab = np.vstack((M1,M2))\n",
        "\tbasis_index = np.append(basis_index,n-1)\n",
        "\treturn newtab,basis_index,Anew,bnew\n",
        "\n",
        "\n",
        "def PRUNEtab(tab,basis_index,numvar):\n",
        "\t'''\n",
        "\tprune and return a basis_index cleared of redundant slacks\n",
        "\t'''\n",
        "\taa = np.asarray(basis_index)\n",
        "\twhile np.sum(aa>=numvar)>=1:\n",
        "\t\ttab,basis_index = prunetab(tab,basis_index,numvar)\n",
        "\t\taa = np.asarray(basis_index)\n",
        "\treturn tab,basis_index\n",
        "\n",
        "\n",
        "def prunetab(tab,basis_index,numvar):\n",
        "\t'''\n",
        "\tm,n original size of the tab, m: original num of constraints, n: original num of vars (not including slack vars)\n",
        "\tdrop the slack variables that enter basis\n",
        "\t'''\n",
        "\tM,N = tab.shape \n",
        "\tfor i in basis_index:\n",
        "\t\tif i>=numvar:\n",
        "            # found a slack variable that enters the basis\n",
        "            # drop the column\n",
        "\t\t\tlset = np.where(abs(tab[1:M,i+1]-1)<1e-8)\n",
        "\t\t\tl = lset[0][0]\n",
        "\t\t\ttab = np.delete(tab,i+1,1)\n",
        "\t\t\ttab = np.delete(tab,l+1,0)\n",
        "\t\t\tbasis_index = list(basis_index)\n",
        "\t\t\tbasis_index.remove(i)\n",
        "\t\t\tfor j in range(len(basis_index)):\n",
        "\t\t\t\tif basis_index[j]>i:\n",
        "\t\t\t\t\tbasis_index[j] -= 1\n",
        "\t\t\tbasis_index = np.asarray(basis_index)\n",
        "           # print 'pruning...'\n",
        "\t\t\treturn tab,basis_index\n",
        "\treturn tab,basis_index"
      ],
      "metadata": {
        "id": "-KQigt2boCvn"
      },
      "id": "-KQigt2boCvn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "SOLVER = 'GUROBI'\n",
        "\n",
        "\n",
        "\n",
        "def computeoptimaltab(A, b, RC, obj, basis_index):\n",
        "\tm,n = A.shape\n",
        "\tassert m == b.size; assert n == RC.size\n",
        "\tB = A[:,basis_index]\n",
        "\ttry:\n",
        "\t\tINV = np.linalg.inv(B)\n",
        "\texcept:\n",
        "\t\tprint('basisindex length:', basis_index.size)\n",
        "\t\tprint('Ashape:', A.shape)\n",
        "\t\traise ValueError\n",
        "\tx = np.dot(INV,b)\n",
        "\tA_ = np.dot(INV,A)\n",
        "\tfirstrow = np.append(-obj,RC)\n",
        "\tsecondrow = np.column_stack((x,A_))\n",
        "\ttab = np.vstack((firstrow,secondrow))\n",
        "\treturn tab\n",
        "\n",
        "\n",
        "def compute_state(A,b,c):\n",
        "\tm,n = A.shape\n",
        "\tassert m == b.size and n == c.size\n",
        "\tA_tilde = np.column_stack((A,np.eye(m)))\n",
        "\tb_tilde = b\n",
        "\tc_tilde = np.append(c,np.zeros(m))\n",
        "\tif SOLVER == 'GUROBI':\n",
        "\t\tobj,sol,basis_index,rc = GurobiSolve(A_tilde,b_tilde,c_tilde)\n",
        "\telif SOLVER == 'SCIPY':\n",
        "\t\tobj,sol,basis_index,rc = ScipyLinProgSolve(A_tilde,b_tilde,c_tilde)\n",
        "\ttab = computeoptimaltab(A_tilde,b_tilde,rc,obj,basis_index)\n",
        "\ttab = roundmarrays(tab)\n",
        "\tx = tab[:,0]\n",
        "\t#print tab\n",
        "\tdone = True\n",
        "\tif np.sum(abs(np.round(x)-x)>1e-2) >= 1:\n",
        "\t\tdone = False\n",
        "\tcuts_a = []\n",
        "\tcuts_b = []\n",
        "\tfor i in range(x.size):\n",
        "\t\tif abs(round(x[i])-x[i])>1e-2: \n",
        "\t\t\t# fractional rows used to compute cut\n",
        "\t\t\tcut_a,cut_b = generatecutzeroth(tab[i,:])\t\n",
        "\t\t\t# a^T x + e^T y >= d\n",
        "\t\t\tassert cut_a.size == m+n\n",
        "\t\t\ta = cut_a[0:n]\n",
        "\t\t\te = cut_a[n:]\n",
        "\t\t\tnewA = np.dot(A.T,e) - a\n",
        "\t\t\tnewb = np.dot(e,b) - cut_b\n",
        "\t\t\tcuts_a.append(newA)\n",
        "\t\t\tcuts_b.append(newb)\n",
        "\tcuts_a,cuts_b = np.array(cuts_a),np.array(cuts_b)\n",
        "\treturn A,b,cuts_a,cuts_b,done,obj,x,tab\n",
        "\n",
        "\n",
        "def roundmarrays(x,delta=1e-7):\n",
        "\t'''\n",
        "\tif certain components of x are very close to integers, round them\n",
        "\t'''\n",
        "\tindex = np.where(abs(np.round(x)-x)<delta)\n",
        "\tx[index] = np.round(x)[index]\n",
        "\treturn x\n",
        "\n",
        "\n",
        "class GurobiOriginalEnv(object):\n",
        "\tdef __init__(self, A, b, c, solution=None, reward_type='simple'):\n",
        "\t\t'''\n",
        "\t\tmin c^T x, Ax <= b, x>=0\n",
        "\t\t'''\n",
        "\t\tself.A0 = A.copy()\n",
        "\t\tself.A = A.copy()\n",
        "\t\tself.b0 = b.copy()\n",
        "\t\tself.b = b.copy()\n",
        "\t\tself.c0 = c.copy()\n",
        "\t\tself.c = c.copy()\n",
        "\t\tself.x = None\n",
        "\t\tself.reward_type = reward_type\n",
        "\t\tassert reward_type in ['simple', 'obj']\n",
        "\n",
        "\t\t# upon init, check if the ip problem can be solved by lp\n",
        "\t\t#try:\n",
        "\t\t#\t_, done = self._reset()\n",
        "\t\t#\tassert done is False\n",
        "\t\t#except NotImplementedError:\n",
        "\t\t#\tprint('the env needs to be initialized with nontrivial ip')\n",
        "\t\t\n",
        "\tdef check_init(self):\n",
        "\t\t_, done = self._reset()\n",
        "\t\treturn done\n",
        "\n",
        "\tdef _reset(self):\n",
        "\t\tself.A,self.b,self.cuts_a,self.cuts_b,self.done,self.oldobj,self.x,self.tab = compute_state(self.A0,self.b0,self.c0)\n",
        "\t\treturn (self.A,self.b,self.c0,self.cuts_a,self.cuts_b), self.done\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\ts, d = self._reset()\n",
        "\t\treturn s\n",
        "\n",
        "\tdef step(self, action):\n",
        "\t\tcut_a,cut_b = self.cuts_a[action,:],self.cuts_b[action]\n",
        "\t\tself.A = np.vstack((self.A,cut_a))\n",
        "\t\tself.b = np.append(self.b,cut_b)\n",
        "\t\ttry:\n",
        "\t\t\tself.A,self.b,self.cuts_a,self.cuts_b,self.done,self.newobj,self.x,self.tab = compute_state(self.A,self.b,self.c0)\n",
        "\t\t\tif self.reward_type == 'simple':\n",
        "\t\t\t\treward = -1.0\n",
        "\t\t\telif self.reward_type == 'obj':\n",
        "\t\t\t\treward = np.abs(self.oldobj - self.newobj)\n",
        "\t\texcept:\n",
        "\t\t\tprint('error in lp iteration')\n",
        "\t\t\tself.done = True\n",
        "\t\t\treward = 0.0\n",
        "\t\tself.oldobj = self.newobj\n",
        "\t\tself.A,self.b,self.cuts_a,self.cuts_b = map(roundmarrays,[self.A,self.b,self.cuts_a,self.cuts_b])\n",
        "\t\treturn \t(self.A,self.b,self.c0,self.cuts_a,self.cuts_b), reward, self.done, {}\n",
        "\n",
        "\tdef max_gap(self):\n",
        "\t\t\"\"\"\n",
        "\t\tthis method computes the max achivable gap\n",
        "\t\t\"\"\"\n",
        "\t\t# preprocessing\n",
        "\t\tA, b, c = self.A0.copy(), self.b0.copy(), self.c0.copy()\n",
        "\t\tm,n = A.shape\n",
        "\t\tassert m == b.size and n == c.size\n",
        "\t\tA_tilde = np.column_stack((A,np.eye(m)))\n",
        "\t\tb_tilde = b\n",
        "\t\tc_tilde = np.append(c,np.zeros(m))\n",
        "\t\tA, b, c = A_tilde, b_tilde, c_tilde\n",
        "\t\t# compute gaps\n",
        "\t\tobjint, solution_int = gurobiutils.GurobiIntSolve(A, b, c)\n",
        "\t\tobjlp, solution_lp, _, _ = gurobiutils.GurobiSolve(A, b, c)\n",
        "\t\treturn np.abs(objint - objlp), solution_int, solution_lp\n",
        "\n",
        "\n",
        "class MultipleEnvs(object):\n",
        "\tdef __init__(self, envs):\n",
        "\t\tself.envs = envs\n",
        "\t\tself.all_indices = list(range(len(self.envs)))\n",
        "\t\tself.available_indices = list(range(len(self.envs)))\n",
        "\t\tself.env_index = None\n",
        "\t\tself.env_now = None\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.env_index = np.random.choice(self.available_indices)\n",
        "\t\tself.available_indices.remove(self.env_index)\n",
        "\t\tif len(self.available_indices) == 0:\n",
        "\t\t\tself.available_indices = self.all_indices[:]\n",
        "\n",
        "\t\tself.env_now = self.envs[self.env_index]\n",
        "\t\treturn self.env_now.reset()\n",
        "\n",
        "\tdef step(self, action):\n",
        "\t\tassert self.env_now is not None\n",
        "\t\treturn self.env_now.step(action)\n",
        "\n",
        "\n",
        "class timelimit_wrapper(object):\n",
        "\tdef __init__(self, env, timelimit):\n",
        "\t\tself.env = env\n",
        "\t\tself.timelimit = timelimit\n",
        "\t\tself.counter = 0\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.counter = 0\n",
        "\t\treturn self.env.reset()\n",
        "\n",
        "\tdef step(self, action):\n",
        "\t\tself.counter += 1\n",
        "\t\tobs, reward, done, info = self.env.step(action)\n",
        "\t\tif self.counter >= self.timelimit:\n",
        "\t\t\tdone = True\n",
        "\t\treturn obs, reward, done, info\n",
        "\n",
        "\n",
        "# some functions for loading instances\n",
        "def make_multiple_env(load_dir, idx_list, timelimit, reward_type):\n",
        "\tenvs = []\n",
        "\tfor idx in idx_list:\n",
        "\t\tprint('loading training instances, dir {} idx {}'.format(load_dir, idx))\n",
        "\t\tA = np.load('{}/A_{}.npy'.format(load_dir, idx))\n",
        "\t\tb = np.load('{}/b_{}.npy'.format(load_dir, idx))\n",
        "\t\tc = np.load('{}/c_{}.npy'.format(load_dir, idx))\n",
        "\t\tenv = timelimit_wrapper(GurobiOriginalEnv(A, b, c, solution=None, reward_type=reward_type), timelimit)\n",
        "\t\tenvs.append(env)\n",
        "\tenv_final = MultipleEnvs(envs)\n",
        "\treturn env_final\n",
        "\n"
      ],
      "metadata": {
        "id": "tTRTnkGYn0ft"
      },
      "id": "tTRTnkGYn0ft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e848e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "9815a4cea8c146608881b9023ebf9bab",
            "74668c7e0f574bba992c95d80f9011fa",
            "24cde24d951e471b90db4870cf4d3fa7",
            "87b2bb9323f44abb8fb9b70b7d08d005",
            "e6959b6a959749bfab9c6ac8182de5d7",
            "cc21ec9be6de42019694fd5b2b6ed151",
            "0bcb4851af304189b53a6187ebc0228a",
            "e1682cb6965e43c2a3200c8e09cc6e84"
          ]
        },
        "id": "a2e848e6",
        "outputId": "cd3f3fb5-545b-434e-f3a6-c5a51c412f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:25oppoyc) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.506 MB of 0.506 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9815a4cea8c146608881b9023ebf9bab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fresh-monkey-529</strong>: <a href=\"https://wandb.ai/orcs4529/uncategorized/runs/25oppoyc\" target=\"_blank\">https://wandb.ai/orcs4529/uncategorized/runs/25oppoyc</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221125_114546-25oppoyc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:25oppoyc). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221125_115145-1hqznmsd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/orcs4529/uncategorized/runs/1hqznmsd\" target=\"_blank\">glad-terrain-530</a></strong> to <a href=\"https://wandb.ai/orcs4529/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/orcs4529/uncategorized/runs/1hqznmsd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f1963417310>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### TRAINING\n",
        "\n",
        "# Setup: You may generate your own instances on which you train the cutting agent.\n",
        "custom_config = {\n",
        "    \"load_dir\"        : 'instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
        "    \"idx_list\"        : list(range(20)),                # take the first 20 instances from the directory\n",
        "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
        "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
        "}\n",
        "\n",
        "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
        "easy_config = {\n",
        "    \"load_dir\"        : 'instances/train_10_n60_m60',\n",
        "    \"idx_list\"        : list(range(10)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
        "hard_config = {\n",
        "    \"load_dir\"        : 'instances/train_100_n60_m60',\n",
        "    \"idx_list\"        : list(range(99)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "\n",
        "test_config = {\n",
        "    \"load_dir\" : 'instances/test_100_n60_m60',\n",
        "    \"idx_list\" : list(range(99)),\n",
        "    \"timelimit\" : 50,\n",
        "    \"reward_type\" : 'obj'\n",
        "}\n",
        "\n",
        "\n",
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bidirectional=False):\n",
        "        super(LSTM_net, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
        "                            bidirectional=bidirectional, batch_first=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        hidden = self.init_hidden()\n",
        "        inputs = torch.FloatTensor(input).view(1, -1, self.input_size)\n",
        "        output, _ = self.lstm(inputs)\n",
        "        # output[-1] is same as last hidden state\n",
        "        output = output[-1].reshape(-1, self.hidden_size)\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1 + int(self.bidirectional), 1, self.hidden_size),\n",
        "                torch.zeros(1 + int(self.bidirectional), 1, self.hidden_size))\n",
        "\n",
        "\n",
        "class Attention_Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, hidden_size2):\n",
        "        super(Attention_Net, self).__init__()\n",
        "        # constrain and cuts dimension\n",
        "        self.input_size = int(input_size)\n",
        "        self.hidden_size = int(hidden_size)\n",
        "        self.hidden_size2 = int(hidden_size2)\n",
        "        self.lstm1 = LSTM_net(input_size, hidden_size)\n",
        "        self.lstm2 = LSTM_net(input_size, hidden_size)\n",
        "        self.linear1 = nn.Linear(self.hidden_size, self.hidden_size2)\n",
        "        self.linear2 = nn.Linear(self.hidden_size2, self.hidden_size2)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, constraints, cuts):\n",
        "        constraints = torch.FloatTensor(constraints)\n",
        "        cuts = torch.FloatTensor(cuts)\n",
        "\n",
        "        # lstm\n",
        "        A_embed = self.lstm1.forward(constraints)\n",
        "        D_embed = self.lstm2.forward(cuts)\n",
        "\n",
        "        # dense\n",
        "        A = self.linear2(self.tanh(self.linear1(A_embed)))\n",
        "        D = self.linear2(self.tanh(self.linear1(D_embed)))\n",
        "\n",
        "        # attention\n",
        "        logits = torch.sum(torch.mm(D, A.T), axis=1)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Policy network will just be copied from lab4 and make small modification\n",
        "class Policy(object):\n",
        "    def __init__(self, input_size, hidden_size, hidden_size2, lr):\n",
        "\n",
        "        self.model = Attention_Net(input_size, hidden_size, hidden_size2)\n",
        "        # DEFINE THE OPTIMIZER\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "    def compute_prob(self, constraints, cuts):\n",
        "        constraints = torch.FloatTensor(constraints)\n",
        "        cuts = torch.FloatTensor(cuts)\n",
        "        prob = torch.nn.functional.softmax(self.model(constraints, cuts), dim=-1)\n",
        "        return prob.cpu().data.numpy()\n",
        "\n",
        "    def _to_one_hot(self, y, num_classes):\n",
        "        \"\"\"\n",
        "        convert an integer vector y into one-hot representation\n",
        "        \"\"\"\n",
        "        scatter_dim = len(y.size())\n",
        "        y_tensor = y.view(*y.size(), -1)\n",
        "        zeros = torch.zeros(*y.size(), num_classes, dtype=y.dtype)\n",
        "        return zeros.scatter(scatter_dim, y_tensor, 1)\n",
        "\n",
        "    def train(self, constraints, cuts, actions, Qs):\n",
        "        \"\"\"\n",
        "        states: numpy array (states)\n",
        "        actions: numpy array (actions)\n",
        "        Qs: numpy array (Q values)\n",
        "        \"\"\"\n",
        "        actions = torch.LongTensor(actions)\n",
        "        Qs = torch.FloatTensor(Qs)\n",
        "\n",
        "        total_loss = 0\n",
        "        # for a bunch of constraints and cuts, need to go one by one\n",
        "        for i in range(len(constraints)):\n",
        "            curr_constraints = constraints[i]\n",
        "            curr_cuts = cuts[i]\n",
        "            curr_action = actions[i]\n",
        "            # COMPUTE probability vector pi(s) for all s in states\n",
        "            logits = self.model(curr_constraints, curr_cuts)\n",
        "            prob = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            # Compute probaility pi(s,a) for all s,a\n",
        "            action_onehot = self._to_one_hot(curr_action, curr_cuts.shape[0])\n",
        "            prob_selected = torch.sum(prob * action_onehot, axis=-1)\n",
        "\n",
        "            # FOR ROBUSTNESS\n",
        "            prob_selected += 1e-8\n",
        "            loss = -torch.mean(Qs[i] * torch.log(prob_selected))\n",
        "            # BACKWARD PASS\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # UPDATE\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.detach().cpu().data.numpy()\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "def discounted_rewards(r, gamma):\n",
        "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "    discounted_r = np.zeros_like(r)\n",
        "    running_sum = 0\n",
        "    for i in reversed(range(0,len(r))):\n",
        "        discounted_r[i] = running_sum * gamma + r[i]\n",
        "        running_sum = discounted_r[i]\n",
        "    return list(discounted_r)\n",
        "\n",
        "\n",
        "def normalization(A, b, E, d):\n",
        "    all_coeff = np.concatenate((A, E), axis=0)\n",
        "    all_constraint = np.concatenate((b, d))\n",
        "    max_1, max_2 = np.max(all_coeff), np.max(all_constraint)\n",
        "    min_1, min_2 = np.min(all_coeff), np.min(all_constraint)\n",
        "    norm_A = (A - min_1) / (max_1 - min_1)\n",
        "    norm_E = (E - min_1) / (max_1 - min_1)\n",
        "    norm_b = (b - min_2) / (max_2 - min_2)\n",
        "\n",
        "    norm_d = (d - min_2) / (max_2 - min_2)\n",
        "\n",
        "    return norm_A, norm_b, norm_E, norm_d\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    training = False\n",
        "    explore = True\n",
        "    PATH = \"models/easy_config_best_model_2.pt\"\n",
        "\n",
        "\n",
        "    # create env\n",
        "    env = make_multiple_env(**test_config)\n",
        "    lr = 1e-2\n",
        "    # initialize networks\n",
        "    input_dim = 61\n",
        "    lstm_hidden = 10\n",
        "    dense_hidden = 64\n",
        "\n",
        "    explore_rate = 1.0\n",
        "    min_explore_rate = 0.01\n",
        "    max_explore_rate = 0.5\n",
        "    explore_decay_rate = 0.01\n",
        "    best_rew = 0\n",
        "\n",
        "    if training:\n",
        "        actor = Policy(input_size=input_dim, hidden_size=lstm_hidden, hidden_size2=dense_hidden, lr=lr)\n",
        "    else:\n",
        "        actor = torch.load(PATH)\n",
        "\n",
        "    sigma = 0.2\n",
        "    gamma = 0.99 # discount\n",
        "    rrecord = []\n",
        "    for e in range(50):\n",
        "        # gym loop\n",
        "        # To keep a record of states actions and reward for each episode\n",
        "        obss_constraint = []  # states\n",
        "        obss_cuts = []\n",
        "        acts = []\n",
        "        rews = []\n",
        "\n",
        "        s = env.reset()   # samples a random instance every time env.reset() is called\n",
        "        d = False\n",
        "        repisode = 0\n",
        "\n",
        "        while not d:\n",
        "\n",
        "            A, b, c0, cuts_a, cuts_b = s\n",
        "\n",
        "            # normalization\n",
        "            A, b, cuts_a, cuts_b = normalization(A, b, cuts_a, cuts_b)\n",
        "\n",
        "            # concatenate [a, b] [e, d]\n",
        "            curr_constraints = np.concatenate((A, b[:, None]), axis=1)\n",
        "            available_cuts = np.concatenate((cuts_a, cuts_b[:, None]), axis=1)\n",
        "\n",
        "            # compute probability distribution\n",
        "            prob = actor.compute_prob(curr_constraints, available_cuts)\n",
        "            prob /= np.sum(prob)\n",
        "\n",
        "            explore_rate = min_explore_rate + \\\n",
        "                           (max_explore_rate - min_explore_rate) * np.exp(-explore_decay_rate * (e))\n",
        "\n",
        "            # epsilon greedy for exploration\n",
        "            if training and explore:\n",
        "                random_num = random.uniform(0, 1)\n",
        "                if random_num <= explore_rate:\n",
        "                    a = np.random.randint(0, s[-1].size, 1)\n",
        "                else:\n",
        "                    #a = np.argmax(prob)\n",
        "                    a = [np.random.choice(s[-1].size,  p=prob.flatten())]\n",
        "            else:\n",
        "                # for testing case, only sample action\n",
        "                a = [np.random.choice(s[-1].size,  p=prob.flatten())]\n",
        "\n",
        "            new_state, r, d, _ = env.step(list(a))\n",
        "            #print('episode', e, 'step', t, 'reward', r, 'action space size', new_state[-1].size, 'action', a)\n",
        "            #a = np.random.randint(0, s[-1].size, 1) # s[-1].size shows the number of actions, i.e., cuts available at state s\n",
        "            #A, b, c0, cuts_a, cuts_b = new_state\n",
        "\n",
        "            obss_constraint.append(curr_constraints)\n",
        "            obss_cuts.append(available_cuts)\n",
        "            acts.append(a)\n",
        "            rews.append(r)\n",
        "            s = new_state\n",
        "            repisode += r\n",
        "\n",
        "        # record rewards and print out to track performance\n",
        "        rrecord.append(np.sum(rews))\n",
        "        returns = discounted_rewards(rews, gamma)\n",
        "        # we only use one trajectory so only one-variate gaussian used here.\n",
        "        Js = returns + np.random.normal(0, 1, len(returns)) / sigma\n",
        "        print(\"episode: \", e)\n",
        "        print(\"sum reward: \", repisode)\n",
        "\n",
        "        # PG update and save best model so far\n",
        "        if training:\n",
        "            if repisode >= best_rew:\n",
        "                best_rew = repisode\n",
        "                torch.save(actor, PATH)\n",
        "\n",
        "            loss = actor.train(obss_constraint, obss_cuts, acts, Js)\n",
        "            print(\"Loss: \", loss)\n",
        "\n",
        "\n",
        "        #wandb logging\n",
        "        wandb.log({\"Discounted Reward\": np.sum(returns)})\n",
        "        fixedWindow = 10\n",
        "        movingAverage = 0\n",
        "        if len(rrecord) >= fixedWindow:\n",
        "            movingAverage = np.mean(rrecord[len(rrecord) - fixedWindow:len(rrecord) - 1])\n",
        "        wandb.log({\"Training reward\": repisode, \"training reward moving average\": movingAverage})\n",
        "\n",
        "\n",
        "\t#if using hard-config make sure to use \"training-hard\" tag in wandb.init in the initialization on top"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "trX8qt3SnbIf",
        "outputId": "cd05dcc4-0f04-4bc6-b56f-a2ce73002941"
      },
      "id": "trX8qt3SnbIf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading training instances, dir instances/test_100_n60_m60 idx 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b026c6cf1816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# create env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_multiple_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# initialize networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8ac4dd1e0fa6>\u001b[0m in \u001b[0;36mmake_multiple_env\u001b[0;34m(load_dir, idx_list, timelimit, reward_type)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading training instances, dir {} idx {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/A_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/b_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/c_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'instances/test_100_n60_m60/A_0.npy'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9815a4cea8c146608881b9023ebf9bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74668c7e0f574bba992c95d80f9011fa",
              "IPY_MODEL_24cde24d951e471b90db4870cf4d3fa7"
            ],
            "layout": "IPY_MODEL_87b2bb9323f44abb8fb9b70b7d08d005"
          }
        },
        "74668c7e0f574bba992c95d80f9011fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6959b6a959749bfab9c6ac8182de5d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cc21ec9be6de42019694fd5b2b6ed151",
            "value": "0.506 MB of 0.506 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "24cde24d951e471b90db4870cf4d3fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bcb4851af304189b53a6187ebc0228a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1682cb6965e43c2a3200c8e09cc6e84",
            "value": 1
          }
        },
        "87b2bb9323f44abb8fb9b70b7d08d005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6959b6a959749bfab9c6ac8182de5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc21ec9be6de42019694fd5b2b6ed151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bcb4851af304189b53a6187ebc0228a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1682cb6965e43c2a3200c8e09cc6e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}